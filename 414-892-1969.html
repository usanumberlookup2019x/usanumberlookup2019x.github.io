<html>
<meta charset="utf-8">
<head>
<title>414-892-1969 Phone Number Lookup</title>
</head>
<body>
414-892-1969

After half a century of human research in the NLP field, AI is finally showing its pride! On May 4th, in the CoQA challenge held by Stanford university, AI's conversational ability was as good as that of human beings. In other words, human interaction with the model is more like interaction with a real person.

The CoQA challenge measures machine performance by understanding text paragraphs and answering a series of interrelated questions that arise during a conversation. This time, the NLP team of Microsoft research Asia and the Redmond voice dialogue team have joined hands to form a golden partnership.

They are the only team in the history of the CoQA challenge that has achieved a human level of model performance! The set system score they submitted on 29 March 2019 corresponded to 89.9/88.0/89.4 for in-domain, out-of-domain and overall F1, respectively, while the human performance of the same set of session questions and answers was 89.4/87.4/88.8, respectively.



Since 2018, there has been a steady stream of good news in the human NLP space. Google launched the BERT language model in October last year and captured STOA results in 11 NLP tasks. In February, OpenAI demonstrated a large-scale unsupervised language model for its training, called gpt-2, which can be extended from the previous article without requiring specific training.

This also explained, at present NLP research and development is entering a golden age!



Microsoft has won the Stanford CoQA challenge again

CoQA is a large set of conversational q&a data from articles in different fields, from which machine learning extracts q&a data for conversational q&a. The goal of the CoQA challenge is to measure a machine's ability to understand text and to test its ability to answer questions in conversations close to humans.

The NLP team previously used the Stanford SQuAD data set to score over 80% of the models in the CoQA domain's F1 data set, up to 80.7%, to set the best performance record in the dialog system model performance challenge. The questions in CoQA are more conversational than those in SQuAD, and the answer can be free-form text to ensure the answers in the conversation are natural.

The conversation problem in CoQA takes the form of a conversation that mimics a human, but is generally short. Each question after the first question is answered according to the first question, which makes the short questions more difficult for machine parsing. For example, suppose you ask the system, "who is the founder of Microsoft?" When you ask follow-up questions like "when was he born? Machine parsing needs to determine that you are still talking about the same topic.

</body>

<html>
